{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Câu 1:\n",
    "Cung cấp bộ dữ liệu Ecoli ecoli.csv trong folder đề thi (thông tin chi tiết và dữ liệu cũng có thể download trên https://www.openml.org/d/1011) với 8 features và bảng kết quả run (https://www.openml.org/t/3874) đã được thực hiện để tham khảo.<br>\n",
    "*Yêu cầu:*<br>\n",
    "Hãy chọn thuật toán phù hợp để xây dựng model dự đoán một mẫu có binaryClass là positive(“P”) hay negative (“N”). Giải thích lý do tại sao bạn chọn thuật toán này? <br>\n",
    "Chú ý: Thực hiện tất cả các bước để giải quyết vấn đề này từ tiền xử lý dữ liệu => báo cáo kết quả."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import pandas and plotting library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mcg</th>\n",
       "      <th>gvh</th>\n",
       "      <th>lip</th>\n",
       "      <th>chg</th>\n",
       "      <th>aac</th>\n",
       "      <th>alm1</th>\n",
       "      <th>alm2</th>\n",
       "      <th>binaryClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.35</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.44</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.46</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.36</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.35</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mcg   gvh   lip  chg   aac  alm1  alm2 binaryClass\n",
       "0  0.49  0.29  0.48  0.5  0.56  0.24  0.35           P\n",
       "1  0.07  0.40  0.48  0.5  0.54  0.35  0.44           P\n",
       "2  0.56  0.40  0.48  0.5  0.49  0.37  0.46           P\n",
       "3  0.59  0.49  0.48  0.5  0.52  0.45  0.36           P\n",
       "4  0.23  0.32  0.48  0.5  0.55  0.25  0.35           P"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"https://raw.githubusercontent.com/tuyenhavan/Course_Data/main/ecoli.csv\", sep=\",\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mcg            0\n",
       "gvh            0\n",
       "lip            0\n",
       "chg            0\n",
       "aac            0\n",
       "alm1           0\n",
       "alm2           0\n",
       "binaryClass    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing data\n",
    "df.isna().sum() # The dataset has no missing data in all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mcg</th>\n",
       "      <th>gvh</th>\n",
       "      <th>lip</th>\n",
       "      <th>chg</th>\n",
       "      <th>aac</th>\n",
       "      <th>alm1</th>\n",
       "      <th>alm2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mcg   gvh   lip  chg   aac  alm1  alm2  target\n",
       "0  0.49  0.29  0.48  0.5  0.56  0.24  0.35       1\n",
       "1  0.07  0.40  0.48  0.5  0.54  0.35  0.44       1\n",
       "2  0.56  0.40  0.48  0.5  0.49  0.37  0.46       1\n",
       "3  0.59  0.49  0.48  0.5  0.52  0.45  0.36       1\n",
       "4  0.23  0.32  0.48  0.5  0.55  0.25  0.35       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode P=1 and N=0\n",
    "df=pd.get_dummies(df)\n",
    "# Reanem the target column\n",
    "df[\"target\"]=df.binaryClass_P\n",
    "# Drop redundant columns\n",
    "df=df.drop([\"binaryClass_N\", \"binaryClass_P\"], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature and target splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:, 0:7]\n",
    "y=df.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building multple models and select the \"best\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list storing all six following models\n",
    "models =[LogisticRegression(), DecisionTreeClassifier(), GaussianNB(), SVC(kernel=\"linear\"), \n",
    "         RandomForestClassifier(n_estimators=200),KNeighborsClassifier(n_neighbors=6)]\n",
    "# Create a empty list to store values from following iterations\n",
    "container=[]\n",
    "# Loop over each model and randomly split dataset 10 times\n",
    "for model in models:\n",
    "    testScore=[] # Test accuracy \n",
    "    trainScore=[]\n",
    "    absScore=[]\n",
    "    for i in range(20):\n",
    "        X_train, X_test, y_train, y_test=train_test_split(X,y, test_size=0.25, random_state=i)\n",
    "        model.fit(X_train, y_train)\n",
    "        modelName=model.__class__.__name__\n",
    "        y_pred=model.predict(X_test)\n",
    "        y_train_pred=model.predict(X_train)\n",
    "        test_score=accuracy_score(y_test,y_pred)\n",
    "        train_score=accuracy_score(y_train,y_train_pred)\n",
    "        abs_score=abs(test_score-train_score)\n",
    "        # Append test_score and train_score, abs_score to testScore, trainScore and absScore\n",
    "        testScore.append(test_score)\n",
    "        trainScore.append(train_score)\n",
    "        absScore.append(abs_score)\n",
    "    container.append([modelName, np.array(testScore).mean()*100, np.array(trainScore).mean()*100, np.array(absScore).mean()*100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_Name</th>\n",
       "      <th>Test_Score</th>\n",
       "      <th>Train_Score</th>\n",
       "      <th>Train_Test_Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>95.416667</td>\n",
       "      <td>95.357143</td>\n",
       "      <td>2.480159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>91.726190</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>8.273810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>67.321429</td>\n",
       "      <td>67.242063</td>\n",
       "      <td>4.246032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>96.071429</td>\n",
       "      <td>96.190476</td>\n",
       "      <td>2.380952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>96.071429</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>96.369048</td>\n",
       "      <td>97.261905</td>\n",
       "      <td>1.884921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model_Name  Test_Score  Train_Score  Train_Test_Difference\n",
       "0      LogisticRegression   95.416667    95.357143               2.480159\n",
       "1  DecisionTreeClassifier   91.726190   100.000000               8.273810\n",
       "2              GaussianNB   67.321429    67.242063               4.246032\n",
       "3                     SVC   96.071429    96.190476               2.380952\n",
       "4  RandomForestClassifier   96.071429   100.000000               3.928571\n",
       "5    KNeighborsClassifier   96.369048    97.261905               1.884921"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe storing model name, train and test accuracy score, etc.\n",
    "df_score=pd.DataFrame(container, columns=[\"Model_Name\",\"Test_Score\",\"Train_Score\",\"Train_Test_Difference\"])\n",
    "df_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Comments**: It is noted that although all three classifiers SVC, RandomForest and KNN had higher accuracy than other models, the KNN classifier had the highest accuracy. In addition, the KNN had least difference in accuracy between training and testing which indicated that the model is not overfitted. However, the KNN model may be sensitive to k, and therefore multiple KNN classifers will be constructed to select \"best\" k and confirm this choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>testScore</th>\n",
       "      <th>trainScore</th>\n",
       "      <th>trainTestDifference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.980159</td>\n",
       "      <td>0.027778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.980159</td>\n",
       "      <td>0.015873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.007937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.011905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.023810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.023810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.019841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   K  testScore  trainScore  trainTestDifference\n",
       "0  2   0.928571    0.984127             0.055556\n",
       "1  3   0.952381    0.980159             0.027778\n",
       "2  4   0.964286    0.980159             0.015873\n",
       "3  5   0.976190    0.968254             0.007937\n",
       "4  6   0.964286    0.976190             0.011905\n",
       "5  7   0.952381    0.976190             0.023810\n",
       "6  8   0.952381    0.976190             0.023810\n",
       "7  9   0.952381    0.972222             0.019841"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build multiple KNN models with k between 1 and 10\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y, test_size=0.25, random_state=12)\n",
    "container=[]\n",
    "for i in range(2,10):\n",
    "    model=KNeighborsClassifier(n_neighbors=i)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred=model.predict(X_test)\n",
    "    y_train_pred=model.predict(X_train)\n",
    "    test_score=accuracy_score(y_test,y_pred)\n",
    "    train_score=accuracy_score(y_train, y_train_pred)\n",
    "    abs_score=abs(test_score-train_score)\n",
    "    container.append([i,test_score, train_score, abs_score])\n",
    "df_knn=pd.DataFrame(container, columns=[\"K\",\"testScore\",\"trainScore\",\"trainTestDifference\"])\n",
    "df_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**remark**: K=5 outperformed all other k in the model while k=4 or 6 can be a good candidate too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is noted that there may be some variables are not contributed to the model. Hence, feature selection needs to be done. SelectKBest is used for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k='all', score_func=<function chi2 at 0x0000029038829820>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestFeat=SelectKBest(score_func=chi2, k=\"all\")\n",
    "bestFeat.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.27507939e+00, 4.05815295e+00, 1.20343697e-01, 1.09930659e-03,\n",
       "       1.03318886e+00, 1.75022468e+01, 5.43886731e+00])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestFeat.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chg</td>\n",
       "      <td>0.001099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lip</td>\n",
       "      <td>0.120344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aac</td>\n",
       "      <td>1.033189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gvh</td>\n",
       "      <td>4.058153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>alm2</td>\n",
       "      <td>5.438867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mcg</td>\n",
       "      <td>9.275079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>alm1</td>\n",
       "      <td>17.502247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Feature      Score\n",
       "3     chg   0.001099\n",
       "2     lip   0.120344\n",
       "4     aac   1.033189\n",
       "1     gvh   4.058153\n",
       "6    alm2   5.438867\n",
       "0     mcg   9.275079\n",
       "5    alm1  17.502247"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat=pd.DataFrame({\"Feature\":X.columns,\"Score\":bestFeat.scores_})\n",
    "df_feat.sort_values(\"Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Noted that three variables lip, chg and aac had the least importance in the SelectKBest*. Rebuilding model with all variables except these three."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebuild KNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>testScore</th>\n",
       "      <th>trainScore</th>\n",
       "      <th>trainTestDifference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.023810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.019841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.019841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.011905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.019841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.023810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.019841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   K  testScore  trainScore  trainTestDifference\n",
       "0  2   0.928571    0.976190             0.047619\n",
       "1  3   0.952381    0.976190             0.023810\n",
       "2  4   0.952381    0.972222             0.019841\n",
       "3  5   0.952381    0.972222             0.019841\n",
       "4  6   0.964286    0.976190             0.011905\n",
       "5  7   0.952381    0.972222             0.019841\n",
       "6  8   0.952381    0.976190             0.023810\n",
       "7  9   0.952381    0.972222             0.019841"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build multiple KNN models with k between 1 and 10\n",
    "\n",
    "X_new=X[[\"mcg\",\"gvh\",\"alm1\",\"alm2\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_new,y, test_size=0.25, random_state=12)\n",
    "container=[]\n",
    "for i in range(2,10):\n",
    "    model=KNeighborsClassifier(n_neighbors=i)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred=model.predict(X_test)\n",
    "    y_train_pred=model.predict(X_train)\n",
    "    test_score=accuracy_score(y_test,y_pred)\n",
    "    train_score=accuracy_score(y_train, y_train_pred)\n",
    "    abs_score=abs(test_score-train_score)\n",
    "    container.append([i,test_score, train_score, abs_score])\n",
    "df_knn=pd.DataFrame(container, columns=[\"K\",\"testScore\",\"trainScore\",\"trainTestDifference\"])\n",
    "df_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is noted that K=6 gives highest accuracy observed for this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a final KNN classification model with K=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalKNN=KNeighborsClassifier(n_neighbors=6)\n",
    "finalKNN.fit(X_train, y_train)\n",
    "# Make prediction on testset\n",
    "y_pred=finalKNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy is 96.4 %\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy\n",
    "overallAccuracy=accuracy_score(y_test,y_pred)*100\n",
    "\n",
    "print(\"Overall Accuracy is {:.3} %\".format(overallAccuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97        48\n",
      "           1       0.95      0.97      0.96        36\n",
      "\n",
      "    accuracy                           0.96        84\n",
      "   macro avg       0.96      0.97      0.96        84\n",
      "weighted avg       0.96      0.96      0.96        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recall and precision\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Both recall and precision had good accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probability \n",
    "y_prob=finalKNN.predict_proba(X_test)\n",
    "p_prob=y_prob[:,1]\n",
    "p_prob\n",
    "fpr, tpr, thresholds=roc_curve(y_test,p_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'True Positive Rate')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([0,1],[0,1], linestyle=\"--\")\n",
    "plt.plot(fpr,tpr, marker=\".\", color=\"r\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.970775462962963"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc(fpr,tpr) # AUC showed good performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final comment: KNN with k=6 showed the most promissing model for this dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Câu 2:**\n",
    "### Cung cấp bộ dữ liệu Cholesterol **dataset_2190_cholesterol.csv** trong folder đề thi (thông tin chi tiết và dữ liệu cũng có thể download trên https://www.openml.org/d/204 ) với 14 features và bảng kết quả run (https://www.openml.org/t/2295 ) đo bằng MAE đã được thực hiện để tham khảo.\n",
    "## Yêu cầu:\n",
    "### Hãy chọn thuật toán phù hợp để xây dựng model dự đoán **chol** (chỉ số cholesterol). Giải thích lý do tại sao bạn chọn thuật toán này?\n",
    "#### Chú ý: Thực hiện tất cả các bước để giải quyết vấn đề này từ tiền xử lý dữ liệu => báo cáo kết quả.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read dataset and examine it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "      <th>chol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  fbs  restecg  thalach  exang  oldpeak  slope ca  \\\n",
       "0   63    1   1       145    1        2      150      0      2.3      3  0   \n",
       "1   67    1   4       160    0        2      108      1      1.5      2  3   \n",
       "2   67    1   4       120    0        2      129      1      2.6      2  2   \n",
       "3   37    1   3       130    0        0      187      0      3.5      3  0   \n",
       "4   41    0   2       130    0        2      172      0      1.4      1  0   \n",
       "\n",
       "  thal  num  chol  \n",
       "0    6    0   233  \n",
       "1    3    2   286  \n",
       "2    7    1   229  \n",
       "3    3    0   250  \n",
       "4    3    0   204  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"https://raw.githubusercontent.com/tuyenhavan/Course_Data/main/dataset_2190_cholesterol.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   fbs       303 non-null    int64  \n",
      " 5   restecg   303 non-null    int64  \n",
      " 6   thalach   303 non-null    int64  \n",
      " 7   exang     303 non-null    int64  \n",
      " 8   oldpeak   303 non-null    float64\n",
      " 9   slope     303 non-null    int64  \n",
      " 10  ca        303 non-null    object \n",
      " 11  thal      303 non-null    object \n",
      " 12  num       303 non-null    int64  \n",
      " 13  chol      303 non-null    int64  \n",
      "dtypes: float64(1), int64(11), object(2)\n",
      "memory usage: 33.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check data type in each variable \n",
    "df.info() # Some variables are in inappropriate data types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on data description given in this website https://www.openml.org/d/204. I have converted its data type in its form.\n",
    "# Replace ? in the \"ca\" column and convert it to numeric data type\n",
    "df[\"ca\"] = df[\"ca\"].str.replace(\"?\",\"4\")\n",
    "df[\"ca\"]=[int(x) for x in df.ca]\n",
    "# # Replace ? in the \"ca\" column and convert it to numeric data type\n",
    "df[\"thal\"]=df[\"thal\"].str.replace(\"?\",\"3\") # Replace with most common values\n",
    "# convert \"cp\", \"restecg\" and \"slope\" to categorical variables. All other variables with binary values keep as numeric \n",
    "df[\"cp\"] =df[\"cp\"].astype(str)\n",
    "df[\"restecg\"] =df[\"restecg\"].astype(str)\n",
    "df[\"slope\"] =df[\"slope\"].astype(str)\n",
    "df[\"sex\"] =df[\"sex\"].astype(str)\n",
    "df[\"fbs\"] =df[\"fbs\"].astype(str)\n",
    "df[\"exang\"] =df[\"exang\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    168\n",
       "7    117\n",
       "6     18\n",
       "Name: thal, dtype: int64"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are two missing values in \"thal\" column\n",
    "df.thal.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "df.isnull().any().sum() # No missing values in this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature and target split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:, 0:len(df.columns)-1]\n",
    "y=df[\"chol\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ca</th>\n",
       "      <th>num</th>\n",
       "      <th>sex_0</th>\n",
       "      <th>sex_1</th>\n",
       "      <th>cp_1</th>\n",
       "      <th>cp_2</th>\n",
       "      <th>...</th>\n",
       "      <th>restecg_1</th>\n",
       "      <th>restecg_2</th>\n",
       "      <th>exang_0</th>\n",
       "      <th>exang_1</th>\n",
       "      <th>slope_1</th>\n",
       "      <th>slope_2</th>\n",
       "      <th>slope_3</th>\n",
       "      <th>thal_3</th>\n",
       "      <th>thal_6</th>\n",
       "      <th>thal_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>145</td>\n",
       "      <td>150</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>160</td>\n",
       "      <td>108</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>120</td>\n",
       "      <td>129</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>130</td>\n",
       "      <td>187</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>130</td>\n",
       "      <td>172</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>45</td>\n",
       "      <td>110</td>\n",
       "      <td>132</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>68</td>\n",
       "      <td>144</td>\n",
       "      <td>141</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>57</td>\n",
       "      <td>130</td>\n",
       "      <td>115</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>130</td>\n",
       "      <td>174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>38</td>\n",
       "      <td>138</td>\n",
       "      <td>173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  trestbps  thalach  oldpeak  ca  num  sex_0  sex_1  cp_1  cp_2  ...  \\\n",
       "0     63       145      150      2.3   0    0      0      1     1     0  ...   \n",
       "1     67       160      108      1.5   3    2      0      1     0     0  ...   \n",
       "2     67       120      129      2.6   2    1      0      1     0     0  ...   \n",
       "3     37       130      187      3.5   0    0      0      1     0     0  ...   \n",
       "4     41       130      172      1.4   0    0      1      0     0     1  ...   \n",
       "..   ...       ...      ...      ...  ..  ...    ...    ...   ...   ...  ...   \n",
       "298   45       110      132      1.2   0    1      0      1     1     0  ...   \n",
       "299   68       144      141      3.4   2    2      0      1     0     0  ...   \n",
       "300   57       130      115      1.2   1    3      0      1     0     0  ...   \n",
       "301   57       130      174      0.0   1    1      1      0     0     1  ...   \n",
       "302   38       138      173      0.0   4    0      0      1     0     0  ...   \n",
       "\n",
       "     restecg_1  restecg_2  exang_0  exang_1  slope_1  slope_2  slope_3  \\\n",
       "0            0          1        1        0        0        0        1   \n",
       "1            0          1        0        1        0        1        0   \n",
       "2            0          1        0        1        0        1        0   \n",
       "3            0          0        1        0        0        0        1   \n",
       "4            0          1        1        0        1        0        0   \n",
       "..         ...        ...      ...      ...      ...      ...      ...   \n",
       "298          0          0        1        0        0        1        0   \n",
       "299          0          0        1        0        0        1        0   \n",
       "300          0          0        0        1        0        1        0   \n",
       "301          0          1        1        0        0        1        0   \n",
       "302          0          0        1        0        1        0        0   \n",
       "\n",
       "     thal_3  thal_6  thal_7  \n",
       "0         0       1       0  \n",
       "1         1       0       0  \n",
       "2         0       0       1  \n",
       "3         1       0       0  \n",
       "4         1       0       0  \n",
       "..      ...     ...     ...  \n",
       "298       0       0       1  \n",
       "299       0       0       1  \n",
       "300       0       0       1  \n",
       "301       1       0       0  \n",
       "302       1       0       0  \n",
       "\n",
       "[303 rows x 25 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=pd.get_dummies(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list storing all six following models\n",
    "models =[DecisionTreeRegressor(), SVR(kernel=\"linear\"), \n",
    "         RandomForestRegressor(n_estimators=200),KNeighborsRegressor(n_neighbors=6), LinearRegression()]\n",
    "# Create a empty list to store values from following iterations\n",
    "container=[]\n",
    "# Loop over each model and randomly split dataset 10 times\n",
    "for model in models:\n",
    "    testScore=[] # Test accuracy \n",
    "    trainScore=[]\n",
    "    absScore=[]\n",
    "    for i in range(20):\n",
    "        X_train, X_test, y_train, y_test=train_test_split(X,y, test_size=0.25, random_state=i)\n",
    "        model.fit(X_train, y_train)\n",
    "        modelName=model.__class__.__name__\n",
    "        y_pred=model.predict(X_test)\n",
    "        y_train_pred=model.predict(X_train)\n",
    "        test_score=model.score(X_test, y_test)\n",
    "        train_score=model.score(X_train,y_train)\n",
    "        abs_score=abs(test_score-train_score)\n",
    "        # Append test_score and train_score, abs_score to testScore, trainScore and absScore\n",
    "        testScore.append(test_score)\n",
    "        trainScore.append(train_score)\n",
    "        absScore.append(abs_score)\n",
    "    container.append([modelName, np.array(testScore).mean(), np.array(trainScore).mean(), np.array(absScore).mean()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_Name</th>\n",
       "      <th>Test_Score</th>\n",
       "      <th>Train_Score</th>\n",
       "      <th>Train_Test_Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>-1.261697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.261697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVR</td>\n",
       "      <td>-0.008655</td>\n",
       "      <td>0.099094</td>\n",
       "      <td>0.117009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>-0.111910</td>\n",
       "      <td>0.857434</td>\n",
       "      <td>0.969344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>-0.133293</td>\n",
       "      <td>0.218283</td>\n",
       "      <td>0.351577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>-0.104797</td>\n",
       "      <td>0.157761</td>\n",
       "      <td>0.262558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model_Name  Test_Score  Train_Score  Train_Test_Difference\n",
       "0  DecisionTreeRegressor   -1.261697     1.000000               2.261697\n",
       "1                    SVR   -0.008655     0.099094               0.117009\n",
       "2  RandomForestRegressor   -0.111910     0.857434               0.969344\n",
       "3    KNeighborsRegressor   -0.133293     0.218283               0.351577\n",
       "4       LinearRegression   -0.104797     0.157761               0.262558"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe storing model name, train and test accuracy score, etc.\n",
    "df_score=pd.DataFrame(container, columns=[\"Model_Name\",\"Test_Score\",\"Train_Score\",\"Train_Test_Difference\"])\n",
    "df_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comments: It is noted that regression did not fit the data well since R squared are negative. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check distribution of chol variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='chol'>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.distplot(df.chol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This dataset was not suitable for regression task since it poorly performed. Alternatively, we can classifiy cholesteron in three classes according to medical practices such as Normal (<200 mg/dL), Slightly risk (200 - 239 mg/dL), high risk ( >=240 mg/dL)** Please see this website for for more information on classification. http://www.scymed.com/en/smnxdj/edzr/edzr9610.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target variable into categorical variable under three class as above. Normal =0, slightly risk=1, and high risk =2\n",
    "\n",
    "def phanloai(a):\n",
    "    mlist=[]\n",
    "    for i in a:\n",
    "        if i<200:\n",
    "            mlist.append(0)\n",
    "        elif 200<=i<=239:\n",
    "            mlist.append(1)\n",
    "        else:\n",
    "            mlist.append(2)\n",
    "    return mlist\n",
    "        \n",
    "mlist=phanloai(df.chol)\n",
    "\n",
    "y_class=pd.Series(mlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building classification model with three classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Create a list storing all six following models\n",
    "models =[LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\"), DecisionTreeClassifier(), GaussianNB(), SVC(kernel=\"rbf\"), \n",
    "         RandomForestClassifier(n_estimators=200),KNeighborsClassifier(n_neighbors=5)]\n",
    "# Create a empty list to store values from following iterations\n",
    "container=[]\n",
    "# Loop over each model and randomly split dataset 10 times\n",
    "for model in models:\n",
    "    testScore=[] # Test accuracy \n",
    "    trainScore=[]\n",
    "    absScore=[]\n",
    "    for i in range(20):\n",
    "        X_train, X_test, y_train, y_test=train_test_split(X,y_class, test_size=0.25, random_state=i)\n",
    "        model.fit(X_train, y_train)\n",
    "        modelName=model.__class__.__name__\n",
    "        y_pred=model.predict(X_test)\n",
    "        y_train_pred=model.predict(X_train)\n",
    "        test_score=accuracy_score(y_test,y_pred)\n",
    "        train_score=accuracy_score(y_train,y_train_pred)\n",
    "        abs_score=abs(test_score-train_score)\n",
    "        # Append test_score and train_score, abs_score to testScore, trainScore and absScore\n",
    "        testScore.append(test_score)\n",
    "        trainScore.append(train_score)\n",
    "        absScore.append(abs_score)\n",
    "    container.append([modelName, np.array(testScore).mean()*100, np.array(trainScore).mean()*100, np.array(absScore).mean()*100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_Name</th>\n",
       "      <th>Test_Score</th>\n",
       "      <th>Train_Score</th>\n",
       "      <th>Train_Test_Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>49.210526</td>\n",
       "      <td>55.660793</td>\n",
       "      <td>8.155576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>62.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>35.657895</td>\n",
       "      <td>42.290749</td>\n",
       "      <td>7.377695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>51.907895</td>\n",
       "      <td>51.343612</td>\n",
       "      <td>5.753246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>45.592105</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>54.407895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>42.828947</td>\n",
       "      <td>61.123348</td>\n",
       "      <td>18.294401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model_Name  Test_Score  Train_Score  Train_Test_Difference\n",
       "0      LogisticRegression   49.210526    55.660793               8.155576\n",
       "1  DecisionTreeClassifier   37.500000   100.000000              62.500000\n",
       "2              GaussianNB   35.657895    42.290749               7.377695\n",
       "3                     SVC   51.907895    51.343612               5.753246\n",
       "4  RandomForestClassifier   45.592105   100.000000              54.407895\n",
       "5    KNeighborsClassifier   42.828947    61.123348              18.294401"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe storing model name, train and test accuracy score, etc.\n",
    "df_score=pd.DataFrame(container, columns=[\"Model_Name\",\"Test_Score\",\"Train_Score\",\"Train_Test_Difference\"])\n",
    "df_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments**: Looking at the table above, it is observed that SVC provided the \"best\" test accuracy with least difference in training and test accuracies. Hence, this model is chosen for further improvement for this dataset although overall it is not fitted dataset well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k='all', score_func=<function chi2 at 0x0000029038829820>)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest \n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "bestFeat=SelectKBest(score_func=chi2, k=\"all\")\n",
    "bestFeat.fit(X,y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fbs_0</td>\n",
       "      <td>0.056057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>thal_3</td>\n",
       "      <td>0.078512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>thal_7</td>\n",
       "      <td>0.115089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>restecg_1</td>\n",
       "      <td>0.261185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>slope_2</td>\n",
       "      <td>0.273405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fbs_1</td>\n",
       "      <td>0.321394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>slope_1</td>\n",
       "      <td>0.337824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oldpeak</td>\n",
       "      <td>0.457895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cp_3</td>\n",
       "      <td>0.828621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cp_4</td>\n",
       "      <td>0.983800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>exang_0</td>\n",
       "      <td>0.990019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cp_2</td>\n",
       "      <td>1.054152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>slope_3</td>\n",
       "      <td>1.233666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cp_1</td>\n",
       "      <td>1.584755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sex_1</td>\n",
       "      <td>1.675102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>exang_1</td>\n",
       "      <td>2.040039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>num</td>\n",
       "      <td>2.361279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ca</td>\n",
       "      <td>2.579045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>thal_6</td>\n",
       "      <td>2.889717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sex_0</td>\n",
       "      <td>3.557433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>restecg_0</td>\n",
       "      <td>5.252997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>restecg_2</td>\n",
       "      <td>5.494267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thalach</td>\n",
       "      <td>6.613989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trestbps</td>\n",
       "      <td>11.655677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>13.401669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature      Score\n",
       "12      fbs_0   0.056057\n",
       "22     thal_3   0.078512\n",
       "24     thal_7   0.115089\n",
       "15  restecg_1   0.261185\n",
       "20    slope_2   0.273405\n",
       "13      fbs_1   0.321394\n",
       "19    slope_1   0.337824\n",
       "3     oldpeak   0.457895\n",
       "10       cp_3   0.828621\n",
       "11       cp_4   0.983800\n",
       "17    exang_0   0.990019\n",
       "9        cp_2   1.054152\n",
       "21    slope_3   1.233666\n",
       "8        cp_1   1.584755\n",
       "7       sex_1   1.675102\n",
       "18    exang_1   2.040039\n",
       "5         num   2.361279\n",
       "4          ca   2.579045\n",
       "23     thal_6   2.889717\n",
       "6       sex_0   3.557433\n",
       "14  restecg_0   5.252997\n",
       "16  restecg_2   5.494267\n",
       "2     thalach   6.613989\n",
       "1    trestbps  11.655677\n",
       "0         age  13.401669"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bestFeat=pd.DataFrame({\"Feature\": X.columns,\"Score\":bestFeat.scores_})\n",
    "df_bestFeat.sort_values(by=[\"Score\"], inplace=True)\n",
    "df_bestFeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only variables with score>=1\n",
    "\n",
    "listFeat=[df_bestFeat.Feature[x] for x in range(len(df_bestFeat)) if df_bestFeat.Score[x]>=5.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new=X[listFeat]\n",
    "y_class=y_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build SVC \n",
    "X_train, X_test, y_train, y_test=train_test_split(X_new, y_class, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcModel=SVC(kernel=\"rbf\")\n",
    "svcModel.fit(X_train,y_train)\n",
    "y_pred=svcModel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Test accuracy is 50.0 % and Overall Train accuracy is 52.0 %\n"
     ]
    }
   ],
   "source": [
    "# Check test and train accuracy\n",
    "testScore=svcModel.score(X_test,y_test)\n",
    "trainScore=svcModel.score(X_train, y_train)\n",
    "\n",
    "print(\"Overall Test accuracy is {:.4} % and Overall Train accuracy is {:.3} %\".format(testScore*100, trainScore*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Create a list storing all six following models\n",
    "models =[LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\"), DecisionTreeClassifier(), GaussianNB(), SVC(kernel=\"rbf\"), \n",
    "         RandomForestClassifier(n_estimators=200),KNeighborsClassifier(n_neighbors=5)]\n",
    "# Create a empty list to store values from following iterations\n",
    "container=[]\n",
    "# Loop over each model and randomly split dataset 10 times\n",
    "for model in models:\n",
    "    testScore=[] # Test accuracy \n",
    "    trainScore=[]\n",
    "    absScore=[]\n",
    "    for i in range(20):\n",
    "        X_train, X_test, y_train, y_test=train_test_split(X_new,y_class, test_size=0.25, random_state=i)\n",
    "        model.fit(X_train, y_train)\n",
    "        modelName=model.__class__.__name__\n",
    "        y_pred=model.predict(X_test)\n",
    "        y_train_pred=model.predict(X_train)\n",
    "        test_score=accuracy_score(y_test,y_pred)\n",
    "        train_score=accuracy_score(y_train,y_train_pred)\n",
    "        abs_score=abs(test_score-train_score)\n",
    "        # Append test_score and train_score, abs_score to testScore, trainScore and absScore\n",
    "        testScore.append(test_score)\n",
    "        trainScore.append(train_score)\n",
    "        absScore.append(abs_score)\n",
    "    container.append([modelName, np.array(testScore).mean()*100, np.array(trainScore).mean()*100, np.array(absScore).mean()*100])\n",
    "    # Create a dataframe storing model name, train and test accuracy score, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score=pd.DataFrame(container, columns=[\"Model_Name\",\"Test_Score\",\"Train_Score\",\"Train_Test_Difference\"])\n",
    "df_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
